{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "source": [
        "!pip install pandas-gbq==0.21.0"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "GKl4updCQ_4U",
        "outputId": "d0b19cad-dede-4901-92bd-c787a1bfa6d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pandas-gbq==0.21.0\n",
            "  Downloading pandas_gbq-0.21.0-py2.py3-none-any.whl.metadata (3.4 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from pandas-gbq==0.21.0) (75.1.0)\n",
            "Requirement already satisfied: db-dtypes<2.0.0,>=1.0.4 in /usr/local/lib/python3.11/dist-packages (from pandas-gbq==0.21.0) (1.4.0)\n",
            "Requirement already satisfied: numpy>=1.16.6 in /usr/local/lib/python3.11/dist-packages (from pandas-gbq==0.21.0) (1.26.4)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.11/dist-packages (from pandas-gbq==0.21.0) (2.2.2)\n",
            "Requirement already satisfied: pyarrow>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from pandas-gbq==0.21.0) (17.0.0)\n",
            "Requirement already satisfied: pydata-google-auth>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from pandas-gbq==0.21.0) (1.9.1)\n",
            "Requirement already satisfied: google-api-core<3.0.0dev,>=2.10.2 in /usr/local/lib/python3.11/dist-packages (from pandas-gbq==0.21.0) (2.19.2)\n",
            "Requirement already satisfied: google-auth>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from pandas-gbq==0.21.0) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from pandas-gbq==0.21.0) (1.2.1)\n",
            "Requirement already satisfied: google-cloud-bigquery<4.0.0dev,>=3.3.5 in /usr/local/lib/python3.11/dist-packages (from pandas-gbq==0.21.0) (3.25.0)\n",
            "Requirement already satisfied: google-cloud-bigquery-storage<3.0.0dev,>=2.16.2 in /usr/local/lib/python3.11/dist-packages (from pandas-gbq==0.21.0) (2.27.0)\n",
            "Requirement already satisfied: packaging>=20.0.0 in /usr/local/lib/python3.11/dist-packages (from pandas-gbq==0.21.0) (24.2)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core<3.0.0dev,>=2.10.2->pandas-gbq==0.21.0) (1.66.0)\n",
            "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0.dev0,>=3.19.5 in /usr/local/lib/python3.11/dist-packages (from google-api-core<3.0.0dev,>=2.10.2->pandas-gbq==0.21.0) (4.25.6)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-api-core<3.0.0dev,>=2.10.2->pandas-gbq==0.21.0) (1.26.0)\n",
            "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in /usr/local/lib/python3.11/dist-packages (from google-api-core<3.0.0dev,>=2.10.2->pandas-gbq==0.21.0) (2.32.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.13.0->pandas-gbq==0.21.0) (5.5.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.13.0->pandas-gbq==0.21.0) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.13.0->pandas-gbq==0.21.0) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from google-auth-oauthlib>=0.7.0->pandas-gbq==0.21.0) (1.3.1)\n",
            "Requirement already satisfied: google-cloud-core<3.0.0dev,>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from google-cloud-bigquery<4.0.0dev,>=3.3.5->pandas-gbq==0.21.0) (2.4.1)\n",
            "Requirement already satisfied: google-resumable-media<3.0dev,>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from google-cloud-bigquery<4.0.0dev,>=3.3.5->pandas-gbq==0.21.0) (2.7.2)\n",
            "Requirement already satisfied: python-dateutil<3.0dev,>=2.7.2 in /usr/local/lib/python3.11/dist-packages (from google-cloud-bigquery<4.0.0dev,>=3.3.5->pandas-gbq==0.21.0) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->pandas-gbq==0.21.0) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->pandas-gbq==0.21.0) (2025.1)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-bigquery<4.0.0dev,>=3.3.5->pandas-gbq==0.21.0) (1.70.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-bigquery<4.0.0dev,>=3.3.5->pandas-gbq==0.21.0) (1.62.3)\n",
            "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /usr/local/lib/python3.11/dist-packages (from google-resumable-media<3.0dev,>=0.6.0->google-cloud-bigquery<4.0.0dev,>=3.3.5->pandas-gbq==0.21.0) (1.6.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.13.0->pandas-gbq==0.21.0) (0.6.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil<3.0dev,>=2.7.2->google-cloud-bigquery<4.0.0dev,>=3.3.5->pandas-gbq==0.21.0) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core<3.0.0dev,>=2.10.2->pandas-gbq==0.21.0) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core<3.0.0dev,>=2.10.2->pandas-gbq==0.21.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core<3.0.0dev,>=2.10.2->pandas-gbq==0.21.0) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core<3.0.0dev,>=2.10.2->pandas-gbq==0.21.0) (2024.12.14)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib>=0.7.0->pandas-gbq==0.21.0) (3.2.2)\n",
            "Downloading pandas_gbq-0.21.0-py2.py3-none-any.whl (26 kB)\n",
            "Installing collected packages: pandas-gbq\n",
            "  Attempting uninstall: pandas-gbq\n",
            "    Found existing installation: pandas-gbq 0.26.1\n",
            "    Uninstalling pandas-gbq-0.26.1:\n",
            "      Successfully uninstalled pandas-gbq-0.26.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "bigframes 1.34.0 requires pandas-gbq>=0.26.0, but you have pandas-gbq 0.21.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed pandas-gbq-0.21.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "_UbmqFDy0lkZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1658e709-6203-41f3-fce2-e25c60b52008"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/adarsh0806/influencer-merchandise-sales?dataset_version_number=1...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 122k/122k [00:00<00:00, 45.9MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "URL da planilha: https://docs.google.com/spreadsheets/d/1K9Px4FfEiiIUN3hbZo8BQZRVU_i2LSig1qRVimS7hno\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 702.33it/s]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\"\"\"\n",
        "ETL PROFISSIONAL: Vendas de E-commerce (Simulador Nível #9)\n",
        "Autor: Eric Pimentel\n",
        "\"\"\"\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from google.auth import default\n",
        "from google.colab import auth\n",
        "from google.cloud import bigquery\n",
        "from googleapiclient.discovery import build\n",
        "import datetime\n",
        "import pandas_gbq\n",
        "import gspread\n",
        "import kagglehub\n",
        "import os\n",
        "import logging\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# Configurar logs\n",
        "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
        "\n",
        "\n",
        "# 1. EXTRAÇÃO\n",
        "\n",
        "def extract_data():\n",
        "    \"\"\"Extrai dados do Kaggle.\"\"\"\n",
        "    try:\n",
        "        logging.info(\" Iniciando extração...\")\n",
        "        path = kagglehub.dataset_download(\"adarsh0806/influencer-merchandise-sales\")\n",
        "        files = os.listdir(path)\n",
        "\n",
        "        for file in files:\n",
        "            if file.endswith(\".csv\"):\n",
        "                df = pd.read_csv(\n",
        "                    os.path.join(path, file),\n",
        "                    delimiter=',',\n",
        "                    parse_dates=['Order Date']\n",
        "                )\n",
        "                logging.info(\" Dados extraídos com sucesso!\")\n",
        "                return df\n",
        "\n",
        "        raise FileNotFoundError(\"Nenhum CSV encontrado.\")\n",
        "\n",
        "    except Exception as e:\n",
        "        logging.error(f\" Erro na extração: {e}\")\n",
        "        return None\n",
        "\n",
        "\n",
        "# 2. TRANSFORMAÇÃO (COM REGRESSÃO LOGÍSTICA)\n",
        "\n",
        "def transform_data(df):\n",
        "    \"\"\"Transforma dados e aplica modelo de previsão.\"\"\"\n",
        "    try:\n",
        "        logging.info(\" Iniciando transformação...\")\n",
        "\n",
        "        # ----- TRADUÇÃO DAS COLUNAS -----\n",
        "        df = df.rename(columns={\n",
        "            'Order ID': 'ID_Pedido',\n",
        "            'Order Date': 'Data_Pedido',\n",
        "            'Product Category': 'Categoria_Produto',\n",
        "            'Buyer Gender': 'Genero_Comprador',\n",
        "            'Buyer Age': 'Idade_Comprador',\n",
        "            'Order Location': 'Localizacao_Pedido',\n",
        "            'International Shipping': 'Envio_Internacional',\n",
        "            'Sales Price': 'Preco_Venda',\n",
        "            'Shipping Charges': 'Taxas_Envio',\n",
        "            'Sales per Unit': 'Vendas_por_Unidade',\n",
        "            'Quantity': 'Quantidade',\n",
        "            'Total Sales': 'Vendas_Totais',\n",
        "            'Rating': 'Avaliacao',\n",
        "            'Review': 'Resenha'\n",
        "        })\n",
        "\n",
        "        # ----- LIMPEZA E ENGENHARIA DE FEATURES -----\n",
        "        df = df.drop_duplicates(subset=['ID_Pedido'])\n",
        "        df['Margem_Lucro'] = df['Vendas_Totais'] - (df['Preco_Venda'] * df['Quantidade'] + df['Taxas_Envio'])\n",
        "        df['Faixa_Etaria'] = pd.cut(df['Idade_Comprador'], bins=[0, 18, 25, 35, 100], labels=['<18', '18-25', '26-35', '35+'])\n",
        "\n",
        "        # ----- CORRIGIR COLUNA 'Envio_Internacional' -----\n",
        "        # Converter \"Yes\"/\"No\" para 1/0\n",
        "        df['Envio_Internacional'] = df['Envio_Internacional'].map({'Yes': 1, 'No': 0}).astype(int)\n",
        "\n",
        "        # Verificar se há valores nulos ou inválidos\n",
        "        if df['Envio_Internacional'].isnull().any():\n",
        "            logging.warning(\"🚨 Valores inválidos encontrados em 'Envio_Internacional'. Substituindo por 0.\")\n",
        "            df['Envio_Internacional'] = df['Envio_Internacional'].fillna(0)\n",
        "\n",
        "        # ----- PREPARAÇÃO PARA REGRESSÃO LOGÍSTICA -----\n",
        "        # Agrupar dados por mês para criar variável alvo (y)\n",
        "        df_mensal = df.groupby(pd.Grouper(key='Data_Pedido', freq='M')).agg({\n",
        "            'Vendas_Totais': 'sum',\n",
        "            'Avaliacao': 'mean',\n",
        "            'Envio_Internacional': 'sum'\n",
        "        }).reset_index()\n",
        "\n",
        "        # Criar variável alvo: 1 se as vendas do próximo mês forem maiores, 0 caso contrário\n",
        "        df_mensal['Target'] = (df_mensal['Vendas_Totais'].shift(-1) > df_mensal['Vendas_Totais']).astype(int)\n",
        "        df_mensal = df_mensal.dropna()\n",
        "\n",
        "        # Definir features (X) e target (y)\n",
        "        X = df_mensal[['Vendas_Totais', 'Avaliacao', 'Envio_Internacional']]\n",
        "        y = df_mensal['Target']\n",
        "\n",
        "        # Treinar modelo\n",
        "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "        model = LogisticRegression()\n",
        "        model.fit(X_train, y_train)\n",
        "\n",
        "        # Fazer previsões\n",
        "        df_mensal['Previsao_Vendas'] = model.predict(X)\n",
        "        logging.info(f\" Modelo treinado! Acurácia: {accuracy_score(y_test, model.predict(X_test)):.2%}\")\n",
        "\n",
        "        # Mesclar previsões com o dataset original\n",
        "        df_mensal['Mes'] = df_mensal['Data_Pedido'].dt.strftime('%Y-%m')\n",
        "        df['Mes'] = df['Data_Pedido'].dt.strftime('%Y-%m')\n",
        "        df = pd.merge(df, df_mensal[['Mes', 'Previsao_Vendas']], on='Mes', how='left')\n",
        "\n",
        "        logging.info(\" Dados transformados e previsões geradas!\")\n",
        "        return df\n",
        "\n",
        "    except Exception as e:\n",
        "        logging.error(f\" Erro na transformação: {e}\")\n",
        "        return None\n",
        "\n",
        "\n",
        "# 3. CARREGAMENTO (ATUALIZADO COM PREVISÕES)\n",
        "\n",
        "def load_data(df):\n",
        "    \"\"\"Carrega dados para Google Sheets e BigQuery.\"\"\"\n",
        "    try:\n",
        "        logging.info(\" Iniciando carregamento...\")\n",
        "        auth.authenticate_user()\n",
        "        credentials, _ = default()\n",
        "        gc = gspread.authorize(credentials)\n",
        "\n",
        "        # Converter a coluna 'Data_Pedido' para string antes de carregar\n",
        "        df['Data_Pedido'] = df['Data_Pedido'].dt.strftime('%Y-%m-%d %H:%M:%S')\n",
        "\n",
        "        # Google Sheets\n",
        "        spreadsheet = gc.create('Vendas_Tratadas_Influenciador02')\n",
        "        spreadsheet.share(None, perm_type='anyone', role='writer')\n",
        "        worksheet = spreadsheet.get_worksheet(0)\n",
        "        worksheet.update([df.columns.tolist()] + df.values.tolist())\n",
        "\n",
        "        # Obter a URL da planilha\n",
        "        spreadsheet_url = spreadsheet.url\n",
        "\n",
        "        # Exibir a URL\n",
        "        print(f\"URL da planilha: {spreadsheet_url}\")\n",
        "\n",
        "        # BigQuery\n",
        "        client = bigquery.Client(project='projeto-vendas-influenciador')\n",
        "        pandas_gbq.to_gbq(\n",
        "            df,\n",
        "            destination_table='projeto_vendas.vendas_tratadas02',\n",
        "            project_id=client.project,\n",
        "            if_exists='replace'\n",
        "        )\n",
        "        logging.info(\" Dados no BigQuery: Prontos para SQL avançado!\")\n",
        "\n",
        "        return True\n",
        "\n",
        "    except Exception as e:\n",
        "        logging.error(f\" Erro no carregamento: {e}\")\n",
        "        return False\n",
        "\n",
        "\n",
        "# 4. EXECUÇÃO PRINCIPAL\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    dados_brutos = extract_data()\n",
        "    if dados_brutos is not None:\n",
        "        dados_tratados = transform_data(dados_brutos)\n",
        "        if dados_tratados is not None:\n",
        "            sucesso = load_data(dados_tratados)\n",
        "            if sucesso:\n",
        "                logging.info(\" Missão cumprida! Previsões no Looker!\")\n",
        "            else:\n",
        "                logging.warning(\" Concluído com erros parciais.\")"
      ]
    }
  ]
}