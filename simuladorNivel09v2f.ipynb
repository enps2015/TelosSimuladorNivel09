{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "source": [
        "!pip install pandas-gbq==0.21.0"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "GKl4updCQ_4U",
        "outputId": "d0b19cad-dede-4901-92bd-c787a1bfa6d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pandas-gbq==0.21.0\n",
            "  Downloading pandas_gbq-0.21.0-py2.py3-none-any.whl.metadata (3.4 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from pandas-gbq==0.21.0) (75.1.0)\n",
            "Requirement already satisfied: db-dtypes<2.0.0,>=1.0.4 in /usr/local/lib/python3.11/dist-packages (from pandas-gbq==0.21.0) (1.4.0)\n",
            "Requirement already satisfied: numpy>=1.16.6 in /usr/local/lib/python3.11/dist-packages (from pandas-gbq==0.21.0) (1.26.4)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.11/dist-packages (from pandas-gbq==0.21.0) (2.2.2)\n",
            "Requirement already satisfied: pyarrow>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from pandas-gbq==0.21.0) (17.0.0)\n",
            "Requirement already satisfied: pydata-google-auth>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from pandas-gbq==0.21.0) (1.9.1)\n",
            "Requirement already satisfied: google-api-core<3.0.0dev,>=2.10.2 in /usr/local/lib/python3.11/dist-packages (from pandas-gbq==0.21.0) (2.19.2)\n",
            "Requirement already satisfied: google-auth>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from pandas-gbq==0.21.0) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from pandas-gbq==0.21.0) (1.2.1)\n",
            "Requirement already satisfied: google-cloud-bigquery<4.0.0dev,>=3.3.5 in /usr/local/lib/python3.11/dist-packages (from pandas-gbq==0.21.0) (3.25.0)\n",
            "Requirement already satisfied: google-cloud-bigquery-storage<3.0.0dev,>=2.16.2 in /usr/local/lib/python3.11/dist-packages (from pandas-gbq==0.21.0) (2.27.0)\n",
            "Requirement already satisfied: packaging>=20.0.0 in /usr/local/lib/python3.11/dist-packages (from pandas-gbq==0.21.0) (24.2)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core<3.0.0dev,>=2.10.2->pandas-gbq==0.21.0) (1.66.0)\n",
            "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0.dev0,>=3.19.5 in /usr/local/lib/python3.11/dist-packages (from google-api-core<3.0.0dev,>=2.10.2->pandas-gbq==0.21.0) (4.25.6)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-api-core<3.0.0dev,>=2.10.2->pandas-gbq==0.21.0) (1.26.0)\n",
            "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in /usr/local/lib/python3.11/dist-packages (from google-api-core<3.0.0dev,>=2.10.2->pandas-gbq==0.21.0) (2.32.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.13.0->pandas-gbq==0.21.0) (5.5.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.13.0->pandas-gbq==0.21.0) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.13.0->pandas-gbq==0.21.0) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from google-auth-oauthlib>=0.7.0->pandas-gbq==0.21.0) (1.3.1)\n",
            "Requirement already satisfied: google-cloud-core<3.0.0dev,>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from google-cloud-bigquery<4.0.0dev,>=3.3.5->pandas-gbq==0.21.0) (2.4.1)\n",
            "Requirement already satisfied: google-resumable-media<3.0dev,>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from google-cloud-bigquery<4.0.0dev,>=3.3.5->pandas-gbq==0.21.0) (2.7.2)\n",
            "Requirement already satisfied: python-dateutil<3.0dev,>=2.7.2 in /usr/local/lib/python3.11/dist-packages (from google-cloud-bigquery<4.0.0dev,>=3.3.5->pandas-gbq==0.21.0) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->pandas-gbq==0.21.0) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->pandas-gbq==0.21.0) (2025.1)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-bigquery<4.0.0dev,>=3.3.5->pandas-gbq==0.21.0) (1.70.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-cloud-bigquery<4.0.0dev,>=3.3.5->pandas-gbq==0.21.0) (1.62.3)\n",
            "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /usr/local/lib/python3.11/dist-packages (from google-resumable-media<3.0dev,>=0.6.0->google-cloud-bigquery<4.0.0dev,>=3.3.5->pandas-gbq==0.21.0) (1.6.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.13.0->pandas-gbq==0.21.0) (0.6.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil<3.0dev,>=2.7.2->google-cloud-bigquery<4.0.0dev,>=3.3.5->pandas-gbq==0.21.0) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core<3.0.0dev,>=2.10.2->pandas-gbq==0.21.0) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core<3.0.0dev,>=2.10.2->pandas-gbq==0.21.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core<3.0.0dev,>=2.10.2->pandas-gbq==0.21.0) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core<3.0.0dev,>=2.10.2->pandas-gbq==0.21.0) (2024.12.14)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib>=0.7.0->pandas-gbq==0.21.0) (3.2.2)\n",
            "Downloading pandas_gbq-0.21.0-py2.py3-none-any.whl (26 kB)\n",
            "Installing collected packages: pandas-gbq\n",
            "  Attempting uninstall: pandas-gbq\n",
            "    Found existing installation: pandas-gbq 0.26.1\n",
            "    Uninstalling pandas-gbq-0.26.1:\n",
            "      Successfully uninstalled pandas-gbq-0.26.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "bigframes 1.34.0 requires pandas-gbq>=0.26.0, but you have pandas-gbq 0.21.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed pandas-gbq-0.21.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "_UbmqFDy0lkZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "94383800-425f-44ca-b432-8691a35a1eb9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "URL da planilha: https://docs.google.com/spreadsheets/d/1kPfKIkysuCrS4gRfwS841mPtFDeRQG2zpAjbmPAffWA\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 756.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "URL do projeto no BigQuery: https://console.cloud.google.com/bigquery?project=projeto-vendas-influenciador&p=projeto-vendas-influenciador&d=projeto_vendas&t=vendas_tratadas_v2&page=table\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "ETL PROFISSIONAL: Vendas de E-commerce (Simulador Nível #9)\n",
        "Autor: Eric Pimentel\n",
        "\"\"\"\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from google.auth import default\n",
        "from google.colab import auth\n",
        "from google.cloud import bigquery\n",
        "from googleapiclient.discovery import build\n",
        "from google.cloud.bigquery import DatasetReference, TableReference\n",
        "import datetime\n",
        "import pandas_gbq\n",
        "import gspread\n",
        "import kagglehub\n",
        "import os\n",
        "import logging\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# Configurar logs\n",
        "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
        "\n",
        "\n",
        "# 1. EXTRAÇÃO\n",
        "\n",
        "def extract_data():\n",
        "    \"\"\"Extrai dados do Kaggle e garante o tipo correto para Data_Pedido.\"\"\"\n",
        "    try:\n",
        "        logging.info(\" Iniciando extração...\")\n",
        "        path = kagglehub.dataset_download(\"adarsh0806/influencer-merchandise-sales\")\n",
        "        files = os.listdir(path)\n",
        "\n",
        "        for file in files:\n",
        "            if file.endswith(\".csv\"):\n",
        "                df = pd.read_csv(os.path.join(path, file), delimiter=',') # Removido parse_dates aqui\n",
        "                # Conversão explícita para datetime com formato\n",
        "                df['Order Date'] = pd.to_datetime(df['Order Date'], format='%Y-%m-%d')\n",
        "                logging.info(\" Dados extraídos com sucesso!\")\n",
        "                return df\n",
        "\n",
        "        raise FileNotFoundError(\"Nenhum CSV encontrado.\")\n",
        "\n",
        "    except Exception as e:\n",
        "        logging.error(f\" Erro na extração: {e}\")\n",
        "        return None\n",
        "\n",
        "\n",
        "# 2. TRANSFORMAÇÃO (COM REGRESSÃO LOGÍSTICA)\n",
        "\n",
        "def transform_data(df):\n",
        "    \"\"\"Transforma dados e aplica modelo de previsão.\"\"\"\n",
        "    try:\n",
        "        logging.info(\" Iniciando transformação...\")\n",
        "\n",
        "        # ----- TRADUÇÃO DAS COLUNAS -----\n",
        "        df = df.rename(columns={\n",
        "            'Order ID': 'ID_Pedido',\n",
        "            'Order Date': 'Data_Pedido',\n",
        "            'Product Category': 'Categoria_Produto',\n",
        "            'Buyer Gender': 'Genero_Comprador',\n",
        "            'Buyer Age': 'Idade_Comprador',\n",
        "            'Order Location': 'Localizacao_Pedido',\n",
        "            'International Shipping': 'Envio_Internacional',\n",
        "            'Sales Price': 'Preco_Venda',\n",
        "            'Shipping Charges': 'Taxas_Envio',\n",
        "            'Sales per Unit': 'Vendas_por_Unidade',\n",
        "            'Quantity': 'Quantidade',\n",
        "            'Total Sales': 'Vendas_Totais',\n",
        "            'Rating': 'Avaliacao',\n",
        "            'Review': 'Resenha'\n",
        "        })\n",
        "\n",
        "         # ----- CONVERSÃO DE TIPOS -----\n",
        "        # Variáveis numéricas para float\n",
        "        colunas_float = ['Preco_Venda', 'Taxas_Envio', 'Vendas_por_Unidade',\n",
        "                        'Vendas_Totais', 'Avaliacao']\n",
        "        for coluna in colunas_float:\n",
        "            df[coluna] = df[coluna].astype(float)\n",
        "\n",
        "        # Variáveis numéricas para int\n",
        "        colunas_int = ['ID_Pedido', 'Idade_Comprador', 'Quantidade']\n",
        "        for coluna in colunas_int:\n",
        "            df[coluna] = df[coluna].astype(int)\n",
        "\n",
        "        # Variáveis categóricas para string\n",
        "        colunas_string = ['Categoria_Produto', 'Genero_Comprador',\n",
        "                         'Localizacao_Pedido', 'Resenha']\n",
        "        for coluna in colunas_string:\n",
        "            df[coluna] = df[coluna].astype(str)\n",
        "\n",
        "        # ----- LIMPEZA E ENGENHARIA DE FEATURES -----\n",
        "        df = df.drop_duplicates(subset=['ID_Pedido'])\n",
        "        df['Margem_Lucro'] = df['Vendas_Totais'] - (df['Preco_Venda'] * df['Quantidade'] + df['Taxas_Envio'])\n",
        "        df['Faixa_Etaria'] = pd.cut(df['Idade_Comprador'], bins=[0, 18, 25, 35, 100], labels=['<18', '18-25', '26-35', '35+'])\n",
        "\n",
        "        # ----- CORRIGIR COLUNA 'Envio_Internacional' -----\n",
        "        df['Envio_Internacional'] = df['Envio_Internacional'].map({'Yes': 1, 'No': 0}).astype(int)\n",
        "\n",
        "        if df['Envio_Internacional'].isnull().any():\n",
        "            logging.warning(\"🚨 Valores inválidos encontrados em 'Envio_Internacional'. Substituindo por 0.\")\n",
        "            df['Envio_Internacional'] = df['Envio_Internacional'].fillna(0)\n",
        "\n",
        "        # ----- PREPARAÇÃO PARA REGRESSÃO LOGÍSTICA -----\n",
        "        df_mensal = df.groupby(pd.Grouper(key='Data_Pedido', freq='M')).agg({\n",
        "            'Vendas_Totais': 'sum',\n",
        "            'Avaliacao': 'mean',\n",
        "            'Envio_Internacional': 'sum'\n",
        "        }).reset_index()\n",
        "\n",
        "        df_mensal['Target'] = (df_mensal['Vendas_Totais'].shift(-1) > df_mensal['Vendas_Totais']).astype(int)\n",
        "        df_mensal = df_mensal.dropna()\n",
        "\n",
        "        X = df_mensal[['Vendas_Totais', 'Avaliacao', 'Envio_Internacional']]\n",
        "        y = df_mensal['Target']\n",
        "\n",
        "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "        model = LogisticRegression()\n",
        "        model.fit(X_train, y_train)\n",
        "\n",
        "        df_mensal['Previsao_Vendas'] = model.predict(X)\n",
        "        logging.info(f\" Modelo treinado! Acurácia: {accuracy_score(y_test, model.predict(X_test)):.2%}\")\n",
        "\n",
        "        df_mensal['Mes'] = df_mensal['Data_Pedido'].dt.strftime('%Y-%m')\n",
        "        df['Mes'] = df['Data_Pedido'].dt.strftime('%Y-%m')\n",
        "        df = pd.merge(df, df_mensal[['Mes', 'Previsao_Vendas']], on='Mes', how='left')\n",
        "\n",
        "        logging.info(\" Dados transformados e previsões geradas!\")\n",
        "        return df\n",
        "\n",
        "    except Exception as e:\n",
        "        logging.error(f\" Erro na transformação: {e}\")\n",
        "        return None\n",
        "\n",
        "\n",
        "# 3. CARREGAMENTO (ATUALIZADO COM PREVISÕES)\n",
        "\n",
        "def load_data(df):\n",
        "    \"\"\"Carrega dados para Google Sheets e BigQuery.\"\"\"\n",
        "    try:\n",
        "        logging.info(\" Iniciando carregamento...\")\n",
        "        auth.authenticate_user()\n",
        "        credentials, _ = default()\n",
        "        gc = gspread.authorize(credentials)\n",
        "\n",
        "        # Converter a coluna 'Data_Pedido' para string\n",
        "        df['Data_Pedido'] = df['Data_Pedido'].dt.strftime('%Y-%m-%d %H:%M:%S')\n",
        "\n",
        "        # Google Sheets\n",
        "        spreadsheet = gc.create('Vendas_Tratadas_Influenciadorv2.0')\n",
        "        spreadsheet.share(None, perm_type='anyone', role='writer')\n",
        "        worksheet = spreadsheet.get_worksheet(0)\n",
        "        worksheet.update([df.columns.tolist()] + df.values.tolist())\n",
        "\n",
        "        print(f\"URL da planilha: {spreadsheet.url}\")\n",
        "\n",
        "        # BigQuery - ESQUEMA DEFINIDO\n",
        "        project_id = 'projeto-vendas-influenciador'\n",
        "        dataset_id = 'projeto_vendas'\n",
        "        table_id = 'vendas_tratadas_v2'\n",
        "\n",
        "        # CONVERSÃO EXPLÍCITA PARA DATETIME64[NS] ANTES DO CARREGAMENTO\n",
        "        df['Data_Pedido'] = pd.to_datetime(df['Data_Pedido']).dt.tz_localize(None) # Correção crucial\n",
        "\n",
        "        # Converter 'Avaliacao' para numérico (opcional, mas recomendado)\n",
        "        df['Avaliacao'] = pd.to_numeric(df['Avaliacao'], errors='coerce')\n",
        "\n",
        "        # Definir o esquema da tabela (opcional, se já definiu no BigQuery)\n",
        "        schema = [\n",
        "            {'name': 'ID_Pedido', 'type': 'INTEGER'},\n",
        "            {'name': 'Data_Pedido', 'type': 'DATE'},  # Tipo DATE\n",
        "            # ... outras colunas ...\n",
        "            {'name': 'Avaliacao', 'type': 'FLOAT'}, # Avaliacao como FLOAT\n",
        "            {'name': 'Mes', 'type': 'STRING'},\n",
        "            {'name': 'Previsao_Vendas', 'type': 'INTEGER'}\n",
        "        ]\n",
        "\n",
        "        # Configurar cliente do BigQuery\n",
        "        client = bigquery.Client(project=project_id)\n",
        "\n",
        "        # Criar dataset se não existir\n",
        "        dataset_ref = client.dataset(dataset_id)\n",
        "        try:\n",
        "            client.get_dataset(dataset_ref)\n",
        "        except Exception:\n",
        "            dataset = bigquery.Dataset(dataset_ref)\n",
        "            dataset.location = \"US\"  # Especificar localização\n",
        "            client.create_dataset(dataset, exists_ok=True)\n",
        "\n",
        "        # Carregar para o BigQuery com esquema definido\n",
        "        pandas_gbq.to_gbq(\n",
        "            df,\n",
        "            destination_table=f\"{dataset_id}.{table_id}\",\n",
        "            project_id=project_id,\n",
        "            if_exists='replace',\n",
        "            table_schema=schema\n",
        "        )\n",
        "        logging.info(\" Dados no BigQuery: Prontos para SQL avançado!\")\n",
        "        print(f\"URL do projeto no BigQuery: https://console.cloud.google.com/bigquery?project={project_id}&p={project_id}&d={dataset_id}&t={table_id}&page=table\")\n",
        "\n",
        "        return True\n",
        "\n",
        "    except Exception as e:\n",
        "        logging.error(f\" Erro no carregamento: {e}\")\n",
        "        return False\n",
        "\n",
        "\n",
        "# 4. EXECUÇÃO PRINCIPAL\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    dados_brutos = extract_data()\n",
        "    if dados_brutos is not None:\n",
        "        dados_tratados = transform_data(dados_brutos)\n",
        "        if dados_tratados is not None:\n",
        "            sucesso = load_data(dados_tratados)\n",
        "            if sucesso:\n",
        "                logging.info(\" Missão cumprida! Previsões no Looker!\")\n",
        "            else:\n",
        "                logging.warning(\" Concluído com erros parciais.\")"
      ]
    }
  ]
}